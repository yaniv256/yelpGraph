{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup working enviroment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.6.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 2.2 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting ijson\n",
      "  Downloading ijson-3.1.post0-cp37-cp37m-manylinux1_x86_64.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 8.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyTigerGraph\n",
      "  Downloading pyTigerGraph-0.0.6.2.tar.gz (14 kB)\n",
      "Collecting urllib3<1.25,>=1.21.1\n",
      "  Downloading urllib3-1.24.3-py2.py3-none-any.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 15.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from kaggle) (1.14.0)\n",
      "Requirement already satisfied: certifi in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from kaggle) (2020.4.5.2)\n",
      "Requirement already satisfied: python-dateutil in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from kaggle) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from kaggle) (4.44.1)\n",
      "Collecting python-slugify\n",
      "  Downloading python-slugify-4.0.0.tar.gz (8.8 kB)\n",
      "Collecting validators\n",
      "  Downloading validators-0.15.0.tar.gz (27 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from requests->kaggle) (2.9)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 9.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator>=3.4.0 in /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/lib/python3.7/site-packages (from validators->pyTigerGraph) (4.4.2)\n",
      "Building wheels for collected packages: kaggle, pyTigerGraph, python-slugify, validators\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.6-py3-none-any.whl size=72859 sha256=aaf3ab191d708a6b4459b4a0d5c91e8951b21750c87883cc05b334442f3f3d17\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/aa/e7/e7/eb3c3d514c33294d77ddd5a856bdd58dc9c1fabbed59a02a2b\n",
      "  Building wheel for pyTigerGraph (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyTigerGraph: filename=pyTigerGraph-0.0.6.2-py3-none-any.whl size=15344 sha256=e65d2421ab7e87d0bb61fe7f65fbc87ae84eb558b1be24ac8f9d329fd65f1cee\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/ef/8c/96/33d5e1491018b2a64bb3280db5836c76ecb6d6c281feefc17e\n",
      "  Building wheel for python-slugify (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-slugify: filename=python_slugify-4.0.0-py2.py3-none-any.whl size=5486 sha256=ecc6c0719ee03cd17bf2786282acb0e25a796499bf0c07285ad249911b540065\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/7c/26/30/5f3d95da00fe94d0c4a5ec5b4ffd2e1ae18545f5fa61752e52\n",
      "  Building wheel for validators (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for validators: filename=validators-0.15.0-py3-none-any.whl size=18371 sha256=15b26b3686c0b97a4f1baf2cbd83fb9196f95af6057775b2374fc3978551951c\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/ff/a1/08/0650ea8df7821ecd87760d16213b53dd23403927a69a388268\n",
      "Successfully built kaggle pyTigerGraph python-slugify validators\n",
      "Installing collected packages: urllib3, text-unidecode, python-slugify, kaggle, ijson, validators, pyTigerGraph\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.25.8\n",
      "    Uninstalling urllib3-1.25.8:\n",
      "      Successfully uninstalled urllib3-1.25.8\n",
      "Successfully installed ijson-3.1.post0 kaggle-1.5.6 pyTigerGraph-0.0.6.2 python-slugify-4.0.0 text-unidecode-1.3 urllib3-1.24.3 validators-0.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle ijson pyTigerGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:14240\n"
     ]
    }
   ],
   "source": [
    "server = 'http://localhost'\n",
    "print(server+':14240')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading gsql client Jar\n",
      "========================\n",
      "Trying version: v2_6_0\n",
      "Connecting to localhost:14240\n",
      "If there is any relative path, it is relative to tigergraph/dev/gdk/gsql\n",
      "---- Global vertices, edges, and all graphs\n",
      "Vertex Types: \n",
      "Edge Types: \n",
      "\n",
      "Graphs: \n",
      "Jobs: \n",
      "\n",
      "\n",
      "JSON API version: v2\n",
      "Syntax version: v1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyTigerGraph as tg\n",
    "\n",
    "conn = tg.TigerGraphConnection(host=server, graphname='yelp')\n",
    "shell = tg.Gsql(conn , certNeeded=False)\n",
    "\n",
    "print(shell.gsql('ls', options=[]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Yelp Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818199bcf85445a696010b260ed21f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import FileUpload\n",
    "upload = FileUpload()\n",
    "upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle\n",
    "with open(\"/home/ubuntu/.kaggle/kaggle.json\", \"w+b\") as i:\n",
    "    i.write(upload.data[0])\n",
    "    \n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading yelp-dataset.zip to /home/ubuntu/yelp\n",
      "100%|█████████████████████████████████████▉| 4.47G/4.48G [01:29<00:00, 79.5MB/s]\n",
      "100%|██████████████████████████████████████| 4.48G/4.48G [01:29<00:00, 53.6MB/s]\n",
      "Archive:  yelp-dataset.zip\n",
      "  inflating: Dataset_Agreement.pdf   \n",
      "  inflating: yelp_academic_dataset_business.json  \n",
      "  inflating: yelp_academic_dataset_checkin.json  \n",
      "  inflating: yelp_academic_dataset_review.json  \n",
      "  inflating: yelp_academic_dataset_tip.json  \n",
      "  inflating: yelp_academic_dataset_user.json  \n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download yelp-dataset/yelp-dataset\n",
    "!unzip yelp-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14911448\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu      41776 Mar 26 01:18 Dataset_Agreement.pdf\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu      21260 Jun 29 21:03 setup_yelp_graph.ipynb\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  152898689 Mar 26 01:18 yelp_academic_dataset_business.json\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  449663480 Mar 26 01:18 yelp_academic_dataset_checkin.json\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 6325565224 Mar 26 01:19 yelp_academic_dataset_review.json\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  263489322 Mar 26 01:31 yelp_academic_dataset_tip.json\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 3268069927 Mar 26 01:32 yelp_academic_dataset_user.json\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 4809540040 Jun 29 21:02 \u001b[0m\u001b[01;31myelp-dataset.zip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm yelp-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define schema helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing autotigergraph.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile autotigergraph.py\n",
    "import ijson\n",
    "\n",
    "def get_first(filename):\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        objects = ijson.items(f, '', multiple_values=True, use_float=True)\n",
    "        first  = objects.__next__()\n",
    "        fields = list(zip(range(len(first)), \n",
    "                        list(first.keys()), \n",
    "                        [type(value).__name__ for value in first.values()]))\n",
    "\n",
    "    return first, fields\n",
    "\n",
    "\n",
    "def guess_vertex(json_object, vertex_name, guess_fields=None):\n",
    "\n",
    "    if guess_fields == None:\n",
    "        guess_fields = json_object.keys()\n",
    "    \n",
    "    type_translate = {'str': 'STRING', 'dict': 'STRING', 'float': 'DOUBLE', \n",
    "                      'bool': 'BOOL', 'int': 'INT'}\n",
    "\n",
    "    gsql_cmd  = 'CREATE VERTEX ' + vertex_name + ' (PRIMARY_ID ' \n",
    "    \n",
    "    for field in guess_fields:\n",
    "\n",
    "        if field == 'date':\n",
    "            gsql_cmd += 'date_time' + ' '\n",
    "            gsql_cmd += 'DATETIME'\n",
    "        else:    \n",
    "            gsql_cmd += field + ' '\n",
    "            gsql_cmd += type_translate[type(json_object[field]).__name__]\n",
    "    \n",
    "        gsql_cmd += ', '\n",
    "\n",
    "    return gsql_cmd[:-2] + ')'\n",
    "\n",
    "\n",
    "def problem_fields_to_str(json_object):\n",
    "\n",
    "    for key, value in json_object.items():\n",
    "        if isinstance(value, dict) or value == None:\n",
    "            json_object[key] = str(value)\n",
    "        if key == 'date':\n",
    "            json_object.pop(key)\n",
    "            json_object['date_time'] = value\n",
    "\n",
    "    return json_object\n",
    "\n",
    "def upsert_json(filename, conn, vertex_name, primary_id, n):\n",
    "\n",
    "    ids = ['']*n\n",
    "    bodies = ['']*n\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        objects = ijson.items(f, '', multiple_values=True, use_float=True)\n",
    "\n",
    "        i = 0\n",
    "        count = 0\n",
    "        for json_object in objects:\n",
    "\n",
    "            if json_object:\n",
    "                ids[i]=json_object.pop(primary_id)\n",
    "                bodies[i]=problem_fields_to_str(json_object)\n",
    "                count += 1\n",
    "                i += 1\n",
    "                if i%n == 0:\n",
    "                    conn.upsertVertices(vertex_name, list(zip(ids, bodies)))\n",
    "                    i = 0\n",
    "\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    conn.upsertVertices(vertex_name, list(zip(ids[:i], bodies[:i])))\n",
    "\n",
    "    return count\n",
    "\n",
    "\n",
    "def create_vertex(shell, json_object, vertex_name, graph_name):\n",
    "\n",
    "    print(shell.gsql('''\n",
    "    drop graph {}\n",
    "    drop vertex {}\n",
    "    {}\n",
    "    create graph {} (*)\n",
    "    ls'''.format(graph_name,\n",
    "                 vertex_name, \n",
    "                 guess_vertex(json_object=json_object, \n",
    "                                  vertex_name=vertex_name),\n",
    "                 graph_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'autotigergraph' from '/home/ubuntu/yelp/autotigergraph.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import autotigergraph as atg\n",
    "import importlib\n",
    "\n",
    "importlib.reload(atg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create schema and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'business_id': 'f9NumwFMBDn751xgFiRbNA',\n",
       "  'name': 'The Range At Lake Norman',\n",
       "  'address': '10913 Bailey Rd',\n",
       "  'city': 'Cornelius',\n",
       "  'state': 'NC',\n",
       "  'postal_code': '28031',\n",
       "  'latitude': 35.4627242,\n",
       "  'longitude': -80.8526119,\n",
       "  'stars': 3.5,\n",
       "  'review_count': 36,\n",
       "  'is_open': 1,\n",
       "  'attributes': {'BusinessAcceptsCreditCards': 'True',\n",
       "   'BikeParking': 'True',\n",
       "   'GoodForKids': 'False',\n",
       "   'BusinessParking': \"{'garage': False, 'street': False, 'validated': False, 'lot': True, 'valet': False}\",\n",
       "   'ByAppointmentOnly': 'False',\n",
       "   'RestaurantsPriceRange2': '3'},\n",
       "  'categories': 'Active Life, Gun/Rifle Ranges, Guns & Ammo, Shopping',\n",
       "  'hours': {'Monday': '10:0-18:0',\n",
       "   'Tuesday': '11:0-20:0',\n",
       "   'Wednesday': '10:0-18:0',\n",
       "   'Thursday': '11:0-20:0',\n",
       "   'Friday': '11:0-20:0',\n",
       "   'Saturday': '11:0-20:0',\n",
       "   'Sunday': '13:0-18:0'}},\n",
       " [(0, 'business_id', 'str'),\n",
       "  (1, 'name', 'str'),\n",
       "  (2, 'address', 'str'),\n",
       "  (3, 'city', 'str'),\n",
       "  (4, 'state', 'str'),\n",
       "  (5, 'postal_code', 'str'),\n",
       "  (6, 'latitude', 'float'),\n",
       "  (7, 'longitude', 'float'),\n",
       "  (8, 'stars', 'float'),\n",
       "  (9, 'review_count', 'int'),\n",
       "  (10, 'is_open', 'int'),\n",
       "  (11, 'attributes', 'dict'),\n",
       "  (12, 'categories', 'str'),\n",
       "  (13, 'hours', 'dict')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'yelp_academic_dataset_business.json'\n",
    "business, fields = atg.get_first(filename)\n",
    "business, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "Trying version: v2_6_0\n",
      "Connecting to localhost:14240\n",
      "If there is any relative path, it is relative to tigergraph/dev/gdk/gsql\n",
      "\n",
      "Restarting gse gpe restpp ...\n",
      "\n",
      "Finish restarting services in 12.564 seconds!\n",
      "The graph yelp is created.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(shell.gsql('create graph yelp (*)', options=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CREATE VERTEX Business (PRIMARY_ID business_id STRING, name STRING, address STRING, city STRING, state STRING, postal_code STRING, latitude DOUBLE, longitude DOUBLE, stars DOUBLE, review_count INT, is_open INT, attributes STRING, categories STRING, hours STRING)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atg.guess_vertex(json_object=business, vertex_name='Business')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "Trying version: v2_6_0\n",
      "Connecting to localhost:14240\n",
      "If there is any relative path, it is relative to tigergraph/dev/gdk/gsql\n",
      "The graph yelp is dropped.\n",
      "The vertex type Business could not be found.\n",
      "The vertex type Business is created.\n",
      "The graph yelp is created.\n",
      "---- Graph yelp\n",
      "Vertex Types: \n",
      "  - VERTEX Business(PRIMARY_ID business_id STRING, name STRING, address STRING, city STRING, state STRING, postal_code STRING, latitude DOUBLE, longitude DOUBLE, stars DOUBLE, review_count INT, is_open INT, attributes STRING, categories STRING, hours STRING) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\"\n",
      "Edge Types: \n",
      "\n",
      "Graphs: \n",
      "  - Graph yelp(Business:v)\n",
      "Jobs: \n",
      "Queries: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "209393"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'yelp_academic_dataset_business.json'\n",
    "vertex_name = 'Business'\n",
    "primary_id = 'business_id'\n",
    "\n",
    "json_object, _ = atg.get_first(filename)\n",
    "atg.create_vertex(shell=shell, json_object=json_object, vertex_name=vertex_name, graph_name='yelp')\n",
    "atg.upsert_json(filename=filename, conn=conn, vertex_name=vertex_name, \n",
    "                primary_id=primary_id, n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "Trying version: v2_6_0\n",
      "Connecting to localhost:14240\n",
      "If there is any relative path, it is relative to tigergraph/dev/gdk/gsql\n",
      "The graph yelp is dropped.\n",
      "The vertex type User could not be found.\n",
      "The vertex type User is created.\n",
      "The graph yelp is created.\n",
      "---- Graph yelp\n",
      "Vertex Types: \n",
      "  - VERTEX Business(PRIMARY_ID business_id STRING, name STRING, address STRING, city STRING, state STRING, postal_code STRING, latitude DOUBLE, longitude DOUBLE, stars DOUBLE, review_count INT, is_open INT, attributes STRING, categories STRING, hours STRING) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\"\n",
      "  - VERTEX User(PRIMARY_ID user_id STRING, name STRING, review_count INT, yelping_since STRING, useful INT, funny INT, cool INT, elite STRING, friends STRING, fans INT, average_stars DOUBLE, compliment_hot INT, compliment_more INT, compliment_profile INT, compliment_cute INT, compliment_list INT, compliment_note INT, compliment_plain INT, compliment_cool INT, compliment_funny INT, compliment_writer INT, compliment_photos INT) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\"\n",
      "Edge Types: \n",
      "\n",
      "Graphs: \n",
      "  - Graph yelp(Business:v, User:v)\n",
      "Jobs: \n",
      "Queries: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1968703"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'yelp_academic_dataset_user.json'\n",
    "vertex_name = 'User'\n",
    "primary_id = 'user_id'\n",
    "\n",
    "json_object, _ = atg.get_first(filename)\n",
    "atg.create_vertex(shell=shell, json_object=json_object, vertex_name=vertex_name, graph_name='yelp')\n",
    "atg.upsert_json(filename=filename, conn=conn, vertex_name=vertex_name, \n",
    "                primary_id=primary_id, n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n",
      "Trying version: v2_6_0\n",
      "Connecting to localhost:14240\n",
      "If there is any relative path, it is relative to tigergraph/dev/gdk/gsql\n",
      "The graph yelp is dropped.\n",
      "The vertex type Review could not be found.\n",
      "The vertex type Review is created.\n",
      "The graph yelp is created.\n",
      "---- Graph yelp\n",
      "Vertex Types: \n",
      "  - VERTEX Business(PRIMARY_ID business_id STRING, name STRING, address STRING, city STRING, state STRING, postal_code STRING, latitude DOUBLE, longitude DOUBLE, stars DOUBLE, review_count INT, is_open INT, attributes STRING, categories STRING, hours STRING) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\"\n",
      "  - VERTEX User(PRIMARY_ID user_id STRING, name STRING, review_count INT, yelping_since STRING, useful INT, funny INT, cool INT, elite STRING, friends STRING, fans INT, average_stars DOUBLE, compliment_hot INT, compliment_more INT, compliment_profile INT, compliment_cute INT, compliment_list INT, compliment_note INT, compliment_plain INT, compliment_cool INT, compliment_funny INT, compliment_writer INT, compliment_photos INT) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\"\n",
      "  - VERTEX Review(PRIMARY_ID review_id STRING, user_id STRING, business_id STRING, stars DOUBLE, useful INT, funny INT, cool INT, text STRING, date_time DATETIME) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\"\n",
      "Edge Types: \n",
      "\n",
      "Graphs: \n",
      "  - Graph yelp(Business:v, User:v, Review:v)\n",
      "Jobs: \n",
      "Queries: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = 'yelp_academic_dataset_review.json'\n",
    "vertex_name = 'Review'\n",
    "primary_id = 'review_id'\n",
    "\n",
    "json_object, _ = atg.get_first(filename)\n",
    "atg.create_vertex(shell=shell, json_object=json_object, vertex_name=vertex_name, graph_name='yelp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8021122"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atg.upsert_json(filename=filename, conn=conn, vertex_name=vertex_name, \n",
    "                primary_id=primary_id, n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_latest_p37)",
   "language": "python",
   "name": "conda_tensorflow2_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
